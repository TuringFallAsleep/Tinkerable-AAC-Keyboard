[PREDICTION_TASK]
word_pred = 
sentence_pred = SENTENCE_KWICKCHAT

[WORD_PREDICTION]
max_pred_num = 4
display_location = Above last pressed key
method = 

[WORD_BM25OKPI]
k1 = 1.5
b = 0.75
epsilon = 0.25

[WORD_BM25L]
k1 = 1.5
b = 0.75
delta = 0.5

[WORD_BM25PLUS]
k1 = 1.5
b = 0.75
delta = 1.0

[WORD_GPT2]
model = distilgpt2
seed = 3

[WORD_ROBERTA]
model = distilroberta-base

[SENTENCE_PREDICTION]
max_pred_num = 4
sentence_entry_approach = Keywords
prediction_approach = Generation

[SENTENCE_RETRIEVAL]
similarity = Semantics

[SENTENCE_TEXT_SIMILARITY]
retri_method = BM25L

[SENTENCE_BM25OKPI]
k1 = 1.6
b = 0.76
epsilon = 0.26

[SENTENCE_BM25L]
k1 = 1.4
b = 0.74
delta = 0.4

[SENTENCE_BM25PLUS]
k1 = 1.5
b = 0.75
delta = 1.0

[SENTENCE_SEMANTIC_SIMILARITY]
sen_retri_seman_model = multi-qa-mpnet-base-dot-v1

[SENTENCE_GENERATION]
method = KWickChat

[SENTENCE_GPT2]
method = Greedy search

[SENTENCE_GPT2_GREEDY]
max_length = 31
no_repeat_n_gram_size = 1

[SENTENCE_GPT2_BEAM]
max_length = 30
no_repeat_n_gram_size = 2
num_of_beams = 5

[SENTENCE_GPT2_TOP_K]
max_length = 30
seed = 0
top_k = 50

[SENTENCE_GPT2_TOP_P]
max_length = 30
seed = 0
top_k = 50
top_p = 0.92

[SENTENCE_KWICKCHAT]
max_length = 21
min_length = 2
seed = 1
temperature = 0.9
top_k = 1
top_p = 0.92
num_of_history = 2
num_of_persona = 2
persona = phd|hci

